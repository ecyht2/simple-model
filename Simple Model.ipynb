{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0a3f895-4eef-4e0b-8029-bf6e5f1a89f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "pip install -U -q transformers torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1840afc-d270-4c8d-abc7-20df11a35183",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import v2 as transforms\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToImage(),\n",
    "    transforms.ToDtype(torch.float32, scale=True),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "batch_size = 5\n",
    "kwargs = {'batch_size': batch_size}\n",
    "\n",
    "dataset1 = MNIST(\"./data\", train=True, download=True, transform=transform)\n",
    "dataset2 = MNIST(\"./data\", train=False, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(dataset1, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(dataset2, **kwargs)\n",
    "\n",
    "plt.imshow(dataset1[0][0].squeeze())\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6240aaf-1709-49d8-822c-7eab069e3cda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-20 14:03:01.199037: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages/transformers/models/auto/image_processing_auto.py:513: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (lin0): Linear(in_features=784, out_features=10, bias=True)\n",
       "  (act): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from simple_model.pytorch_model import Model\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "net = Model()\n",
    "net = net.to(device)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d727933b-cccb-47bc-ae41-0f5e2cc15059",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOC 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12000/12000 [00:46<00:00, 259.77it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import zeros\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm\n",
    "\n",
    "EPOCH = 1\n",
    "\n",
    "optimizer = optim.Adadelta(net.parameters(), lr=1.0)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n",
    "net.train()\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    print(f\"EPOC {epoch + 1}/{EPOCH}\")\n",
    "    for data, target in tqdm(train_loader):\n",
    "        data, target_tensor = data.to(device), zeros(target.shape[0], 10).to(device)\n",
    "        for batch_id, idx in enumerate(target):\n",
    "            target_tensor[batch_id, idx] = 1.0\n",
    "        optimizer.zero_grad()\n",
    "        output = net(data)\n",
    "        loss = F.cross_entropy(output, target_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a99d17f-248b-4074-a3ec-68f1a246db16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:05<00:00, 374.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.5931, Accuracy: 8987/10000 (90%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "net.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for data, target in tqdm(test_loader):\n",
    "        target = target.to(device)\n",
    "        data, target_tensor = data.to(device), zeros(target.shape[0], 10).to(device)\n",
    "        for batch_id, idx in enumerate(target):\n",
    "            target_tensor[batch_id, idx] = 1.0\n",
    "        output = net(data)\n",
    "        test_loss += F.cross_entropy(output, target_tensor, reduction='sum').item()  # sum up batch loss\n",
    "        pred = net.get_guess(output)  # get the index of the max log-probability\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "\n",
    "print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "torch.save(net.state_dict(), \"simple_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bc1f31c-dfae-4f04-b80f-147aab240be7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APAACzBVBJJwAO9dnp/wm8damu6Dw5dRjGf9IKw/+hkVPffCnWNJa7XVNV0Kxa1hErrNe/M2cnYqgElsAHpjkc1wlAODkV694W8c654t8M6n4TuvEctrrFw0cun3c0/lq+3AMJcDK5AyOeTkd+fPvGFn4gsvEtzF4m89tUG1ZJJjuMgUBVYN/EMKOe9YVXtK0bUtdvVs9LsZ7y4YgbIULYycZPoPc8V6lpfwh0/w7p66z8RdXj0y2z8llC4aWQ+mRn8lz9RXPfE3x1pvi46TYaPZTQadpMJghluWDSyrhQM9SMBe5Oc5NcBV7Tda1XRZJJNK1O8sXkG12tZ2iLD0JUjNQ3l9eahN517dT3MvTfNIXb16n6mq9Ff/2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA90lEQVR4AWNgGMyAWUhIqK5jvdSy/9/rQe5kgTlWjs3KRiAYxHsyKfDzxYMgFiOIAALDvfwQBsO/pK8Mz97fhPLAlNDtvyBwbNv3j8jCUHbAnOy/f89yM2jPwiLJwMc4628UqgQTnPvp/0eGFAQXLg5lcO/764YuhuArf3y4IAfmfoQwlBX44e/fckkMYaiA7q6/f6dJ45IViP3zdzcuSQaGn39/OkBl4WEL4euFmLIwXDuETav6lKfAIPy1DYucRNFdUPCe9MOUE3e6CpI6FogZSEKrwbFyOIATQ5v5mkcgXV9auVGlwK4NDGRguL75b88HVDla8QBFF16ADQA8sQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+trwt4W1TxfrcOl6VDvlc5eRvuRL3Zj2A/wD1V0Xj74YXvgeKG5S+TU7NmMU00MRUW8oCnY/JAzu455x0FcHVnTrC51XUrbT7OMyXNzKsUaDuxOBXrmveMYfhfpk/gfwsG/tCJ1e/1TOC8pwWVR2GMLnIxg9+aboGsX/jvwD8SLrX7tpXjitrqPaAio6iTGAOMHYo98eteOV0ngC8t7D4gaDd3cyQ28V5G0kjnCqM9SfSvRvFXwjgttb1LxDr/i6xs9Hup3uY5QpeaYMxbaqjAJwe2fpXDeJ/Fdk+nHw34Whez8PKweTzADNeSA/6yRuuPReAPT046iiiiv/Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABDklEQVR4AWNgGHhgPP/vfCMczjB49+fPn7fYJc0e//3z/uUfSzZMaS6bB3/+/jkV8udvFUSSCUnNzAMyQJ4Rz0EGXQxJY29GxkOljC/OT2JiRNICZoLcspnHu1KUgeHvZzQHqy39+/JCCETH3z9LUbSyb/rzwV0YZCcQ/P1zGMKAkpZ//tjDBdAlj/3dB5dj+P/3CJgD9YqPwf9NCMl//y8gOAwMoX+eScL47O1/d/HAOCA69M99GJe9+c9DdxgHTIf+mQjlGyz9sxZFioEh7O9DiEjRu7+L0OSAxv6cZCAbuunh3/vLLTAl//x5eh0Yl0ea0KUYGGSO/wHG1p+XMJtRVUg2ACV7VVEFB4IHAKxwbkRtVspVAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "data = MNIST('./data')\n",
    "test = [data[0][0], data[1][0]]\n",
    "\n",
    "display(test[0])\n",
    "display(test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce497216-b547-43c7-b521-9340dbac6277",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from simple_model import SimpleModel, SimpleModelConfig\n",
    "\n",
    "SimpleModelConfig.register_for_auto_class(\"AutoConfig\")\n",
    "SimpleModel.register_for_auto_class(\"AutoModel\")\n",
    "SimpleModel.register_for_auto_class(\"AutoModelForImageClassification\")\n",
    "\n",
    "simple_model_config = SimpleModelConfig()\n",
    "simple_model = SimpleModel(simple_model_config)\n",
    "simple_model.model.load_state_dict(net.state_dict())\n",
    "\n",
    "simple_model.save_pretrained(\"simple-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f6283d6-0599-4ab8-bd16-00f625f1fd20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['simple-model/preprocessor_config.json']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from simple_model import SimpleModelProcessor\n",
    "\n",
    "SimpleModelProcessor.register_for_auto_class(\"AutoProcessor\")\n",
    "SimpleModelProcessor.register_for_auto_class(\"AutoImageProcessor\")\n",
    "\n",
    "processor = SimpleModelProcessor()\n",
    "processor.save_pretrained(\"simple-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "834bbc22-fdf9-4823-9990-6187d2e6239f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassifierOutput(loss=None, logits=tensor([[9.1995e-08, 4.8777e-19, 5.6915e-12, 4.4407e-01, 1.0203e-23, 9.9994e-01,\n",
       "         2.6973e-09, 6.2208e-08, 9.9618e-11, 1.7044e-18],\n",
       "        [1.0000e+00, 1.4955e-26, 5.8023e-15, 3.7160e-11, 6.1818e-26, 1.7974e-10,\n",
       "         1.5453e-13, 8.8908e-15, 1.8227e-14, 1.8407e-19]]), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    test_input = processor(test)\n",
    "    test_output = simple_model(**test_input)\n",
    "\n",
    "test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17609b00-b7da-41e4-967a-e52ec6de163b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': '5', 'score': 0.2213965207338333},\n",
       "  {'label': '3', 'score': 0.1269868016242981},\n",
       "  {'label': '0', 'score': 0.08145209401845932},\n",
       "  {'label': '7', 'score': 0.08145209401845932},\n",
       "  {'label': '1', 'score': 0.08145208656787872}],\n",
       " [{'label': '0', 'score': 0.23196934163570404},\n",
       "  {'label': '1', 'score': 0.08533674478530884},\n",
       "  {'label': '2', 'score': 0.08533674478530884},\n",
       "  {'label': '3', 'score': 0.08533674478530884},\n",
       "  {'label': '4', 'score': 0.08533674478530884}]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"image-classification\",\n",
    "    model=simple_model,\n",
    "    image_processor=processor,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "pipe.save_pretrained(\"simple-model\")\n",
    "pipe(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec808c94-dddc-49dc-94dc-0eface7024ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassifierOutput(loss=None, logits=tensor([[9.1995e-08, 4.8777e-19, 5.6915e-12, 4.4407e-01, 1.0203e-23, 9.9994e-01,\n",
       "         2.6973e-09, 6.2208e-08, 9.9618e-11, 1.7044e-18],\n",
       "        [1.0000e+00, 1.4955e-26, 5.8023e-15, 3.7160e-11, 6.1818e-26, 1.7974e-10,\n",
       "         1.5453e-13, 8.8908e-15, 1.8227e-14, 1.8407e-19]]), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoConfig, AutoModel, AutoProcessor\n",
    "\n",
    "output_processor = AutoProcessor.from_pretrained(\n",
    "    \"simple-model\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "output_model = AutoModel.from_pretrained(\n",
    "    \"simple-model\",\n",
    "    # Loading config manually as it is registered in library\n",
    "    config=AutoConfig.from_pretrained(\"simple-model\"),\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_input = processor(test)\n",
    "    test_output = output_model(**test_input)\n",
    "\n",
    "test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40cb4a22-0c15-4501-aae2-8ad60c80ce9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': '5', 'score': 0.2213965207338333},\n",
       "  {'label': '3', 'score': 0.1269868016242981},\n",
       "  {'label': '0', 'score': 0.08145209401845932},\n",
       "  {'label': '7', 'score': 0.08145209401845932},\n",
       "  {'label': '1', 'score': 0.08145208656787872}],\n",
       " [{'label': '0', 'score': 0.23196934163570404},\n",
       "  {'label': '1', 'score': 0.08533674478530884},\n",
       "  {'label': '2', 'score': 0.08533674478530884},\n",
       "  {'label': '3', 'score': 0.08533674478530884},\n",
       "  {'label': '4', 'score': 0.08533674478530884}]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "output_pipeline = pipeline(\n",
    "    \"image-classification\",\n",
    "    model=\"simple-model\",\n",
    "    image_processor=\"simple-model\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "output_pipeline(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8b82923-3633-4586-a8ec-f96ca02066ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install -U -q \"optimum[exporters]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59f3271c-5e32-4d64-a678-a2b94bd19913",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages/transformers/models/auto/image_processing_auto.py:513: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'simple_model.pytorch_model' from '/home/studio-lab-user/sagemaker-studiolab-notebooks/simple-model/simple_model/pytorch_model.py'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import simple_model\n",
    "\n",
    "reload(simple_model)\n",
    "reload(simple_model.configuration_simple_model)\n",
    "reload(simple_model.modeling_simple_model)\n",
    "reload(simple_model.processing_simple_model)\n",
    "reload(simple_model.pytorch_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57b80d47-578a-4a81-9093-2031a94508d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing the argument `library_name` to `get_supported_tasks_for_model_type` is required, but got library_name=None. Defaulting to `transformers`. An error will be raised in a future version of Optimum if `library_name` is not provided.\n",
      "/opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages/torch/onnx/utils.py:2135: UserWarning: Provided key last_hidden_state for dynamic axes is not a valid input/output name\n",
      "  warnings.warn(\n",
      "Using framework PyTorch: 2.4.1+cu121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX Inputs: {'image': {0: 'batch_size', 1: 'num_channels', 2: 'height', 3: 'width'}}\n",
      "ONNX Outputs: OrderedDict([('logits', {0: 'batch_size'})])\n",
      "ONNX Opset: 11\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "number of output names provided (1) exceeded number of outputs (0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 51\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m export \u001b[38;5;28;01mas\u001b[39;00m onnx_export\n\u001b[1;32m     36\u001b[0m onnx_export(\n\u001b[1;32m     37\u001b[0m     output_model,\n\u001b[1;32m     38\u001b[0m     (onnx_config\u001b[38;5;241m.\u001b[39mgenerate_dummy_inputs(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m     opset_version\u001b[38;5;241m=\u001b[39monnx_config\u001b[38;5;241m.\u001b[39mDEFAULT_ONNX_OPSET,\n\u001b[1;32m     49\u001b[0m )\n\u001b[0;32m---> 51\u001b[0m onnx_inputs, onnx_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43monnx_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msimple-model.onnx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43monnx_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDEFAULT_ONNX_OPSET\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_channels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mheight\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwidth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages/optimum/exporters/onnx/convert.py:881\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, config, output, opset, device, input_shapes, disable_dynamic_axes_fix, dtype, no_dynamic_axes, do_constant_folding, model_kwargs)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config\u001b[38;5;241m.\u001b[39mis_torch_support_available:\n\u001b[1;32m    876\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MinimumVersionError(\n\u001b[1;32m    877\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported PyTorch version for this model. Minimum required is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39mMIN_TORCH_VERSION\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    878\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m         )\n\u001b[0;32m--> 881\u001b[0m     export_output \u001b[38;5;241m=\u001b[39m \u001b[43mexport_pytorch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mno_dynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mno_dynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_tf_available() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mtype\u001b[39m(model), TFPreTrainedModel):\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages/optimum/exporters/onnx/convert.py:577\u001b[0m, in \u001b[0;36mexport_pytorch\u001b[0;34m(model, config, opset, output, device, input_shapes, no_dynamic_axes, do_constant_folding, model_kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m         dynamix_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(chain(inputs\u001b[38;5;241m.\u001b[39mitems(), config\u001b[38;5;241m.\u001b[39moutputs\u001b[38;5;241m.\u001b[39mitems()))\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;66;03m# Export can work with named args but the dict containing named args has to be the last element of the args\u001b[39;00m\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;66;03m# tuple.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m     \u001b[43monnx_export\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdummy_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_posix\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamix_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;66;03m# check if external data was exported\u001b[39;00m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;66;03m# TODO: this is quite inefficient as we load in memory if models are <2GB without external data\u001b[39;00m\n\u001b[1;32m    590\u001b[0m onnx_model \u001b[38;5;241m=\u001b[39m onnx\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mstr\u001b[39m(output), load_external_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages/torch/onnx/utils.py:551\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions, autograd_inlining, dynamo)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    547\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    548\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExport destination must be specified for torchscript-onnx export.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    549\u001b[0m     )\n\u001b[0;32m--> 551\u001b[0m \u001b[43m_export\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_opsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_opsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mautograd_inlining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograd_inlining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages/torch/onnx/utils.py:1648\u001b[0m, in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m   1645\u001b[0m     dynamic_axes \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1646\u001b[0m _validate_dynamic_axes(dynamic_axes, model, input_names, output_names)\n\u001b[0;32m-> 1648\u001b[0m graph, params_dict, torch_out \u001b[38;5;241m=\u001b[39m \u001b[43m_model_to_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1650\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1651\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1652\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1653\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1654\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1655\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_do_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1656\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfixed_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1657\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1658\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1659\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1661\u001b[0m \u001b[38;5;66;03m# TODO: Don't allocate a in-memory string for the protobuf\u001b[39;00m\n\u001b[1;32m   1662\u001b[0m defer_weight_export \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1663\u001b[0m     export_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _exporter_states\u001b[38;5;241m.\u001b[39mExportTypes\u001b[38;5;241m.\u001b[39mPROTOBUF_FILE\n\u001b[1;32m   1664\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages/torch/onnx/utils.py:1226\u001b[0m, in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[1;32m   1216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(out, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_quantized\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m out \u001b[38;5;129;01min\u001b[39;00m output_tensors):\n\u001b[1;32m   1217\u001b[0m         _C\u001b[38;5;241m.\u001b[39m_jit_pass_onnx_assign_output_shape(\n\u001b[1;32m   1218\u001b[0m             graph,\n\u001b[1;32m   1219\u001b[0m             output_tensors,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1223\u001b[0m             GLOBALS\u001b[38;5;241m.\u001b[39mexport_onnx_opset_version,\n\u001b[1;32m   1224\u001b[0m         )\n\u001b[0;32m-> 1226\u001b[0m \u001b[43m_set_input_and_output_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m params_dict \u001b[38;5;241m=\u001b[39m _get_named_param_dict(graph, params)\n\u001b[1;32m   1229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1230\u001b[0m     do_constant_folding\n\u001b[1;32m   1231\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m GLOBALS\u001b[38;5;241m.\u001b[39mexport_onnx_opset_version\n\u001b[1;32m   1232\u001b[0m     \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m _constants\u001b[38;5;241m.\u001b[39mONNX_CONSTANT_FOLDING_MIN_OPSET\n\u001b[1;32m   1233\u001b[0m ):\n",
      "File \u001b[0;32m/opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages/torch/onnx/utils.py:1793\u001b[0m, in \u001b[0;36m_set_input_and_output_names\u001b[0;34m(graph, input_names, output_names)\u001b[0m\n\u001b[1;32m   1790\u001b[0m             node\u001b[38;5;241m.\u001b[39msetDebugName(name)\n\u001b[1;32m   1792\u001b[0m set_names(\u001b[38;5;28mlist\u001b[39m(graph\u001b[38;5;241m.\u001b[39minputs()), input_names, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1793\u001b[0m \u001b[43mset_names\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages/torch/onnx/utils.py:1770\u001b[0m, in \u001b[0;36m_set_input_and_output_names.<locals>.set_names\u001b[0;34m(node_list, name_list, descriptor)\u001b[0m\n\u001b[1;32m   1768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1769\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(name_list) \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlen\u001b[39m(node_list):\n\u001b[0;32m-> 1770\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1771\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumber of \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m names provided (\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m) exceeded number of \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124ms (\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1772\u001b[0m         \u001b[38;5;241m%\u001b[39m (descriptor, \u001b[38;5;28mlen\u001b[39m(name_list), descriptor, \u001b[38;5;28mlen\u001b[39m(node_list))\n\u001b[1;32m   1773\u001b[0m     )\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;66;03m# Mark if the output node DebugName is set before.\u001b[39;00m\n\u001b[1;32m   1776\u001b[0m output_node_set \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: number of output names provided (1) exceeded number of outputs (0)"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from itertools import chain\n",
    "\n",
    "from optimum.exporters import TasksManager\n",
    "from optimum.exporters.onnx import export\n",
    "from optimum.exporters.tasks import supported_tasks_mapping\n",
    "from transformers import AutoConfig, AutoModel, AutoProcessor\n",
    "\n",
    "from simple_model.configuration_simple_model import SimpleModelOnnxConfig\n",
    "\n",
    "output_config = AutoConfig.from_pretrained(\"simple-model\")\n",
    "output_model = AutoModel.from_pretrained(\n",
    "    \"simple-model\",\n",
    "    config=output_config,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "onnx_config = SimpleModelOnnxConfig(output_config, task=\"image-classification\")\n",
    "print(f\"ONNX Inputs: {onnx_config.inputs}\")\n",
    "print(f\"ONNX Outputs: {onnx_config.outputs}\")\n",
    "print(f\"ONNX Opset: {onnx_config.DEFAULT_ONNX_OPSET}\")\n",
    "\n",
    "TasksManager._SUPPORTED_MODEL_TYPE[\"simple-model\"] = {\n",
    "    \"onnx\": {\n",
    "        \"image-classification\": SimpleModelOnnxConfig\n",
    "    }\n",
    "}\n",
    "\n",
    "onnx_config_constructor = TasksManager.get_exporter_config_constructor(\n",
    "    \"onnx\",\n",
    "    output_model,\n",
    "    task=\"image-classification\"\n",
    ")\n",
    "onnx_config = onnx_config_constructor(output_model.config)\n",
    "\n",
    "from torch.onnx import export as onnx_export\n",
    "onnx_export(\n",
    "    output_model,\n",
    "    (onnx_config.generate_dummy_inputs(**{\n",
    "        \"num_channels\": 1,\n",
    "        \"height\": 28,\n",
    "        \"width\": 28\n",
    "    }),),\n",
    "    f=Path(\"simple-model.onnx\").as_posix(),\n",
    "    input_names=[\"image\"],\n",
    "    output_names=[\"logits\"],\n",
    "    dynamic_axes=dict(chain(onnx_config.ordered_inputs(output_model).items(), onnx_config.outputs.items())),\n",
    "    do_constant_folding=False,\n",
    "    opset_version=onnx_config.DEFAULT_ONNX_OPSET,\n",
    ")\n",
    "\n",
    "onnx_inputs, onnx_outputs = export(\n",
    "    output_model,\n",
    "    onnx_config,\n",
    "    Path(\"simple-model.onnx\"),\n",
    "    onnx_config.DEFAULT_ONNX_OPSET,\n",
    "    input_shapes={\n",
    "        \"num_channels\": 1,\n",
    "        \"height\": 28,\n",
    "        \"width\": 28\n",
    "    },\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sagemaker-distribution:Python",
   "language": "python",
   "name": "conda-env-sagemaker-distribution-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
